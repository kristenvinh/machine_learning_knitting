{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb3c698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "563fa9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4x/ptbsqx910ss5p1lzy1fn39g40000gn/T/ipykernel_99226/2094244286.py:78: DtypeWarning: Columns (5,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(INPUT_CSV)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26022 total image links, splitting into 261 batches.\n",
      "\n",
      "--- Processing chunk 1 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1: 100%|██████████| 100/100 [00:01<00:00, 87.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  8 failures in this batch.\n",
      "\n",
      "--- Processing chunk 2 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2: 100%|██████████| 100/100 [00:01<00:00, 87.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  8 failures in this batch.\n",
      "\n",
      "--- Processing chunk 3 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3: 100%|██████████| 100/100 [00:02<00:00, 37.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  18 failures in this batch.\n",
      "\n",
      "--- Processing chunk 4 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4: 100%|██████████| 100/100 [00:02<00:00, 46.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  16 failures in this batch.\n",
      "\n",
      "--- Processing chunk 5 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5: 100%|██████████| 100/100 [00:01<00:00, 67.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  10 failures in this batch.\n",
      "\n",
      "--- Processing chunk 6 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 6: 100%|██████████| 100/100 [00:00<00:00, 140.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  5 failures in this batch.\n",
      "\n",
      "--- Processing chunk 7 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 7: 100%|██████████| 100/100 [00:00<00:00, 332.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  2 failures in this batch.\n",
      "\n",
      "--- Processing chunk 8 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 8: 100%|██████████| 100/100 [00:00<00:00, 4049.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing chunk 9 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 9: 100%|██████████| 100/100 [00:00<00:00, 608.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  1 failures in this batch.\n",
      "\n",
      "--- Processing chunk 10 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 10: 100%|██████████| 100/100 [00:02<00:00, 37.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  17 failures in this batch.\n",
      "\n",
      "--- Processing chunk 11 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 11: 100%|██████████| 100/100 [00:04<00:00, 24.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  29 failures in this batch.\n",
      "\n",
      "--- Processing chunk 12 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 12: 100%|██████████| 100/100 [00:01<00:00, 51.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  13 failures in this batch.\n",
      "\n",
      "--- Processing chunk 13 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 13: 100%|██████████| 100/100 [00:01<00:00, 62.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  10 failures in this batch.\n",
      "\n",
      "--- Processing chunk 14 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 14: 100%|██████████| 100/100 [00:01<00:00, 92.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  8 failures in this batch.\n",
      "\n",
      "--- Processing chunk 15 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 15: 100%|██████████| 100/100 [00:02<00:00, 48.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  14 failures in this batch.\n",
      "\n",
      "--- Processing chunk 16 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 16: 100%|██████████| 100/100 [00:29<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  9 failures in this batch.\n",
      "\n",
      "--- Processing chunk 17 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 17: 100%|██████████| 100/100 [00:29<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  13 failures in this batch.\n",
      "\n",
      "--- Processing chunk 18 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 18: 100%|██████████| 100/100 [00:29<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  16 failures in this batch.\n",
      "\n",
      "--- Processing chunk 19 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 19: 100%|██████████| 100/100 [00:27<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  25 failures in this batch.\n",
      "\n",
      "--- Processing chunk 20 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 20: 100%|██████████| 100/100 [00:30<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  12 failures in this batch.\n",
      "\n",
      "--- Processing chunk 21 of 261 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 21:   8%|▊         | 8/100 [00:02<00:27,  3.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4x/ptbsqx910ss5p1lzy1fn39g40000gn/T/ipykernel_99226/2094244286.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mrun_batch_downloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/4x/ptbsqx910ss5p1lzy1fn39g40000gn/T/ipykernel_99226/2094244286.py\u001b[0m in \u001b[0;36mrun_batch_downloader\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mchunk_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n--- Processing chunk {chunk_number} of {len(list_of_dfs)} ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mfailures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfailures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mall_failed_downloads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4x/ptbsqx910ss5p1lzy1fn39g40000gn/T/ipykernel_99226/2094244286.py\u001b[0m in \u001b[0;36mdownload_batch\u001b[0;34m(df_chunk, chunk_num)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "INPUT_CSV = '/Users/kristenvinh/Documents/Github_repos/machine_learning_knitting/EDA/Final Sweaters.csv'\n",
    "OUTPUT_DIR = '/Volumes/Extreme Pro/knitting_photos'\n",
    "FAILED_LOG = 'failed_downloads.csv' # File to log failed attempts\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "# --- Configuration ---\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# List of possible extensions to check for resume logic\n",
    "POSSIBLE_EXTENSIONS = ['.jpg', '.png', '.gif']\n",
    "\n",
    "MIME_TYPE_MAP = {\n",
    "    'image/jpeg': '.jpg',\n",
    "    'image/png': '.png',\n",
    "    'image/gif': '.gif',\n",
    "}\n",
    "\n",
    "# --- Main Script ---\n",
    "def download_batch(df_chunk, chunk_num):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    batch_failures = []\n",
    "\n",
    "    for index, row in tqdm(df_chunk.iterrows(), total=df_chunk.shape[0], desc=f\"Batch {chunk_num}\"):\n",
    "        sweater_id = row['ID']\n",
    "        image_url = row['Photo']\n",
    "\n",
    "        # --- **KEY FIX: ROBUST RESUME LOGIC** ---\n",
    "        # Check if a file for this ID already exists with ANY of the possible extensions.\n",
    "        already_exists = False\n",
    "        for ext in POSSIBLE_EXTENSIONS:\n",
    "            if os.path.exists(os.path.join(OUTPUT_DIR, f\"{sweater_id}{ext}\")):\n",
    "                already_exists = True\n",
    "                break # Found it, no need to check further\n",
    "        \n",
    "        if already_exists:\n",
    "            continue # Skip to the next image\n",
    "        # --- End of Fix ---\n",
    "\n",
    "        try:\n",
    "            response = requests.get(image_url, headers=headers, timeout=20)\n",
    "            if response.status_code != 200:\n",
    "                raise requests.exceptions.HTTPError(f\"HTTP Status {response.status_code}\")\n",
    "\n",
    "            content_type = response.headers.get('content-type', '').lower()\n",
    "            \n",
    "            file_extension = None\n",
    "            for mime, ext in MIME_TYPE_MAP.items():\n",
    "                if mime in content_type:\n",
    "                    file_extension = ext\n",
    "                    break\n",
    "\n",
    "            if not file_extension:\n",
    "                raise TypeError(f\"Unknown image Content-Type: {content_type}\")\n",
    "\n",
    "            output_path = os.path.join(OUTPUT_DIR, f\"{sweater_id}{file_extension}\")\n",
    "            \n",
    "            with open(output_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            time.sleep(0.1)\n",
    "\n",
    "        except (requests.exceptions.RequestException, requests.exceptions.HTTPError, TypeError) as e:\n",
    "            batch_failures.append({'sweater_id': sweater_id, 'image_url': image_url, 'error': str(e)})\n",
    "\n",
    "    return batch_failures\n",
    "\n",
    "def run_batch_downloader():\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_CSV)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{INPUT_CSV}' not found.\")\n",
    "        return\n",
    "        \n",
    "    num_chunks = int(np.ceil(len(df) / BATCH_SIZE))\n",
    "    list_of_dfs = np.array_split(df, num_chunks)\n",
    "    \n",
    "    print(f\"Loaded {len(df)} total image links, splitting into {len(list_of_dfs)} batches.\")\n",
    "    all_failed_downloads = []\n",
    "\n",
    "    for i, chunk_df in enumerate(list_of_dfs):\n",
    "        chunk_number = i + 1\n",
    "        print(f\"\\n--- Processing chunk {chunk_number} of {len(list_of_dfs)} ---\")\n",
    "        failures = download_batch(chunk_df, chunk_number)\n",
    "        if failures:\n",
    "            all_failed_downloads.extend(failures)\n",
    "            print(f\"⚠️  {len(failures)} failures in this batch.\")\n",
    "        \n",
    "    if all_failed_downloads:\n",
    "        pd.DataFrame(all_failed_downloads).to_csv(FAILED_LOG, index=False)\n",
    "        print(f\"\\n--- Process Complete ---\")\n",
    "        print(f\"{len(all_failed_downloads)} total images failed. See '{FAILED_LOG}'.\")\n",
    "    else:\n",
    "        print(\"\\n--- Process Complete ---\")\n",
    "        print(\"All images downloaded successfully!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_batch_downloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a8166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
